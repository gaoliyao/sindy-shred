{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-overview",
   "metadata": {},
   "source": [
    "# SINDy-SHRED: Synthetic Data Example\n",
    "\n",
    "This notebook demonstrates SINDy-SHRED on a synthetic toy dataset using the `SINDySHRED` class. The class handles data preprocessing, model training, and post-hoc SINDy discovery automatically.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**SHRED** (SHallow REcurrent Decoder) models combine a recurrent layer (GRU) with a shallow decoder network to reconstruct high-dimensional spatio-temporal fields from sensor measurements.\n",
    "\n",
    "**SINDy-SHRED** extends this by integrating Sparse Identification of Nonlinear Dynamics (SINDy) to learn interpretable governing equations:\n",
    "\n",
    "$$\\dot{z} = \\Theta(z) \\xi$$\n",
    "\n",
    "## Synthetic Data\n",
    "\n",
    "The synthetic data uses the **FitzHugh-Nagumo Model** with spatially delayed copies:\n",
    "\n",
    "$$\\dot{v} = v - \\frac{1}{3}v^3 - w + I_{ext}$$\n",
    "$$\\dot{w} = \\frac{1}{\\tau}(v + a - bw)$$\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Data Generation\n",
    "3. Model Configuration and Training\n",
    "4. SINDy Discovery\n",
    "5. Evaluation\n",
    "6. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Local modules\n",
    "from sindy_shred import SINDySHRED\n",
    "import plotting\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = \"results/synthetic_data\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-header",
   "metadata": {},
   "source": [
    "### Device and Seed Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-config",
   "metadata": {},
   "source": [
    "### Plotting Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pcolor_kwargs = {\n",
    "    \"vmin\": -3,\n",
    "    \"vmax\": 3,\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "    \"rasterized\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "Generate synthetic spatio-temporal data from the FitzHugh-Nagumo model with spatially delayed copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamics-header",
   "metadata": {},
   "source": [
    "### Define Dynamical System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamics-def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs_FNM(t, x, tau, a, b, Iext):\n",
    "    \"\"\"FitzHugh-Nagumo Model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t : float\n",
    "        Time (unused, for ODE solver interface).\n",
    "    x : array-like\n",
    "        State vector [v, w].\n",
    "    tau : float\n",
    "        Time constant.\n",
    "    a, b : float\n",
    "        Model parameters.\n",
    "    Iext : float\n",
    "        External input current.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dx : array-like\n",
    "        Time derivatives [dv/dt, dw/dt].\n",
    "    \"\"\"\n",
    "    v, w = x\n",
    "    vdot = v - (v**3) / 3 - w + Iext\n",
    "    wdot = (1 / tau) * (v + a - b * w)\n",
    "    return np.array([vdot, wdot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-header",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time integration parameters\n",
    "T = 64\n",
    "dt_solve = 0.0001 * 8\n",
    "t_solution = np.arange(0, T, dt_solve)\n",
    "\n",
    "# FitzHugh-Nagumo parameters\n",
    "x0 = np.array([-1.110, -0.125])\n",
    "tau1 = 2\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "Iext = 0.65\n",
    "\n",
    "# Solve the ODE\n",
    "solution_fn = solve_ivp(\n",
    "    rhs_FNM, [0, T], x0, t_eval=t_solution, args=(tau1, a, b, Iext)\n",
    ")\n",
    "\n",
    "print(f\"FitzHugh-Nagumo solution shape: {solution_fn.y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-spatial-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatially delayed copies\n",
    "num_space_dims = 10\n",
    "delays = np.linspace(0, 2, num_space_dims)  # delays in time units\n",
    "uv_spatial = np.zeros((len(t_solution), 2 * num_space_dims))\n",
    "\n",
    "for i in range(num_space_dims):\n",
    "    delay_steps = int(delays[i] / dt_solve)\n",
    "    if delay_steps == 0:\n",
    "        uv_spatial[:, 2 * i : 2 * i + 2] = solution_fn.y.T\n",
    "    else:\n",
    "        # Pad with initial condition and shift\n",
    "        uv_spatial[:, 2 * i : 2 * i + 2] = np.vstack(\n",
    "            [np.tile(x0, (delay_steps, 1)), solution_fn.y.T[:-delay_steps, :]]\n",
    "        )\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "substep = 50\n",
    "uv_spatial = uv_spatial[0::substep, :]\n",
    "t_solution = t_solution[0::substep]\n",
    "time = t_solution\n",
    "dt_data = time[1] - time[0]\n",
    "\n",
    "# Get dimensions\n",
    "n_space_dims = uv_spatial.shape[1]\n",
    "n_time = uv_spatial.shape[0]\n",
    "\n",
    "# Final data matrix (space x time for visualization)\n",
    "data_original = uv_spatial.T\n",
    "space_dim = np.arange(n_space_dims)\n",
    "\n",
    "print(f\"Data shape (space x time): {data_original.shape}\")\n",
    "print(f\"Time step: {dt_data:.6f}\")\n",
    "print(f\"Number of time samples: {n_time}\")\n",
    "print(f\"Spatial dimension: {n_space_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-data-header",
   "metadata": {},
   "source": [
    "### Visualize Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "\n",
    "ax.pcolormesh(time, space_dim, data_original, **pcolor_kwargs)\n",
    "ax.set_title(r\"Spatio-temporal data $\\mathbf{x}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the data visualization plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/data_original.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/data_original.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved data plot to {RESULTS_DIR}/data_original.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. Model Configuration and Training\n",
    "\n",
    "Configure the SINDy-SHRED model using the `SINDySHRED` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "### Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor configuration (fixed for reproducibility)\n",
    "sensor_locations = np.array([5, 14, 7])\n",
    "num_sensors = len(sensor_locations)\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 2\n",
    "poly_order = 3\n",
    "\n",
    "# Data split configuration\n",
    "lags = 120\n",
    "train_length = 750 // 4\n",
    "validate_length = 0\n",
    "\n",
    "# Prepare data (transpose to time x space, subsample)\n",
    "load_X = copy.deepcopy(data_original)\n",
    "load_X = load_X.T[::4]  # Subsample\n",
    "dt = dt_data * 4\n",
    "lags = lags // 4\n",
    "t_plot = time[::4]\n",
    "\n",
    "# SINDy threshold\n",
    "threshold = 0.0\n",
    "\n",
    "print(f\"Data shape after preprocessing: {load_X.shape}\")\n",
    "print(f\"Number of sensors: {num_sensors}\")\n",
    "print(f\"Latent dimension: {latent_dim}\")\n",
    "print(f\"Trajectory length (lags): {lags}\")\n",
    "print(f\"Training length: {train_length}\")\n",
    "print(f\"Time step: {dt:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor time series\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(t_plot, load_X[:, sensor_locations], color='b', alpha=0.7)\n",
    "ax.axvline(t_plot[train_length], color='k', linestyle='--', label='Train/Test split')\n",
    "ax.axvline(t_plot[lags], color='r', linestyle=':', label='Lag window')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Sensor value')\n",
    "ax.set_title('Sensor Time Series')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "### Initialize and Train Model\n",
    "\n",
    "The `SINDySHRED` class handles data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SINDySHRED(\n",
    "    latent_dim=latent_dim, \n",
    "    poly_order=poly_order,\n",
    "    ode_order=1,  # 1st order ODE: z' = f(z)\n",
    "    num_epochs=600,\n",
    "    verbose=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    num_sensors,\n",
    "    dt,\n",
    "    load_X,\n",
    "    lags,\n",
    "    train_length,\n",
    "    validate_length,\n",
    "    sensor_locations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sindy-header",
   "metadata": {},
   "source": [
    "## 4. SINDy Discovery\n",
    "\n",
    "Discover sparse governing equations from the learned latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-discover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SINDy identification\n",
    "model.sindy_identify(threshold=threshold, plot_result=True)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"Latent Space: SINDy-SHRED vs Identified Model\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the latent comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved latent comparison plot to {RESULTS_DIR}/latent_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auto-tune-header",
   "metadata": {},
   "source": [
    "### Auto-Tune Threshold (Adaptive/Nonparametric)\n",
    "\n",
    "Alternatively, use `auto_tune_threshold()` to automatically determine the best threshold.\n",
    "By default it uses a nonparametric approach:\n",
    "1. First computes the least-squares solution (threshold=0)\n",
    "2. Uses `scale_factor * max(|coefficients|)` as the max threshold\n",
    "3. Tests `n_thresholds` evenly spaced values and picks the best stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auto-tune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-tune threshold using nonparametric approach\n",
    "# This computes least-squares solution first, then determines threshold range adaptively\n",
    "best_threshold, tune_results = model.auto_tune_threshold(\n",
    "    adaptive=True,           # Use nonparametric approach (default)\n",
    "    scale_factor=0.2,        # Max threshold = 0.3 * max(|coefficients|)\n",
    "    n_thresholds=10,         # Test 10 evenly spaced thresholds\n",
    "    metric=\"sparsity_stable\", # Pick sparsest stable model\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.4f}\")\n",
    "print(f\"Tested thresholds: {tune_results['thresholds']}\")\n",
    "print(f\"Sparsity at each: {tune_results['sparsity']}\")\n",
    "print(f\"Stability at each: {tune_results['stable']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "true-eqns-header",
   "metadata": {},
   "source": [
    "### True Governing Equations\n",
    "\n",
    "For reference, the true governing equations are:\n",
    "\n",
    "**FitzHugh-Nagumo Model:**\n",
    "$$\\dot{v} = v - \\frac{1}{3}v^3 - w + 0.65$$\n",
    "$$\\dot{w} = \\frac{1}{\\tau}(v + 0.7 - 0.8w)$$\n",
    "\n",
    "with time constant $\\tau = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate reconstruction performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test reconstruction error using new API\n",
    "test_recons = model.sensor_recon(data_type=\"test\", return_scaled=False)\n",
    "test_ground_truth = model._scaler.inverse_transform(\n",
    "    model._test_data.Y.detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "relative_error = model.relative_error(test_recons, test_ground_truth)\n",
    "print(f\"Test set relative reconstruction error: {relative_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.pcolormesh(test_ground_truth.T, **pcolor_kwargs)\n",
    "ax.set_title(\"Ground Truth\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolormesh(test_recons.T, **pcolor_kwargs)\n",
    "ax.set_title(\"SINDy-SHRED Reconstruction\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time step\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the reconstruction comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/reconstruction_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/reconstruction_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved reconstruction comparison plot to {RESULTS_DIR}/reconstruction_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6f8aa",
   "metadata": {},
   "source": [
    "### Sensor-Level Predictions\n",
    "\n",
    "Compare real vs predicted at individual spatial locations (sensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-spatial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict latent trajectories using SINDy model and decode to physical space\n",
    "x_predict = model.predict_latent()  # SINDy prediction in latent space\n",
    "sindy_physical = model.decode_to_physical(x_predict)  # Decode to physical space\n",
    "sindy_physical = model._scaler.inverse_transform(sindy_physical)  # Unscale\n",
    "\n",
    "print(f\"SINDy prediction shape: {x_predict.shape}\")\n",
    "print(f\"Decoded physical shape: {sindy_physical.shape}\")\n",
    "\n",
    "# Plot sensor-level comparisons: Ground Truth vs SINDy Prediction\n",
    "fig, axes = plotting.plot_sensor_predictions(\n",
    "    test_ground_truth,\n",
    "    sindy_physical[:len(test_ground_truth)],\n",
    "    sensor_locations=np.arange(n_space_dims),  # All spatial dims\n",
    "    rows=2,\n",
    "    cols=5,\n",
    "    save_path=f\"{RESULTS_DIR}/sensor_predictions_grid.pdf\"\n",
    ")\n",
    "fig.suptitle(\"Sensor-Level: Ground Truth vs SINDy Prediction\")\n",
    "fig.tight_layout()\n",
    "print(f\"Saved sensor predictions plot to {RESULTS_DIR}/sensor_predictions_grid.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated SINDy-SHRED on synthetic FitzHugh-Nagumo data:\n",
    "\n",
    "1. Generated toy data from FitzHugh-Nagumo model with spatial delays\n",
    "2. Used the `SINDySHRED` class for streamlined model training\n",
    "3. Discovered sparse governing equations that approximate the true dynamics\n",
    "4. Achieved accurate reconstruction on held-out test data\n",
    "5. **Saved all results** to the `results/synthetic_data/` folder\n",
    "\n",
    "### Saved Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `shred_model.pt` | Trained SHRED neural network weights |\n",
    "| `latent_train.npy` | Latent trajectories from training data |\n",
    "| `latent_test.npy` | Latent trajectories from test data |\n",
    "| `latent_sindy_predict.npy` | SINDy-predicted latent trajectories |\n",
    "| `sindy_coefficients.npy` | Learned SINDy coefficient matrix |\n",
    "| `sindy_feature_names.txt` | Names of SINDy library terms |\n",
    "| `config.npy` | Model configuration and hyperparameters |\n",
    "| `data_original.npy` | Original spatio-temporal data |\n",
    "| `*.pdf/*.png` | Visualization plots |\n",
    "\n",
    "The `SINDySHRED` class simplifies the workflow compared to manual data preprocessing and model setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the trained model, latent space values, and learned SINDy model to the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latent space trajectories\n",
    "gru_outs_train = model.gru_normalize(data_type=\"train\")\n",
    "gru_outs_train_np = gru_outs_train.detach().cpu().numpy()\n",
    "\n",
    "gru_outs_test = model.gru_normalize(data_type=\"test\")\n",
    "gru_outs_test_np = gru_outs_test.detach().cpu().numpy()\n",
    "\n",
    "# Save the trained SHRED model\n",
    "torch.save(model._shred.state_dict(), f\"{RESULTS_DIR}/shred_model.pt\")\n",
    "print(f\"Saved SHRED model to {RESULTS_DIR}/shred_model.pt\")\n",
    "\n",
    "# Save latent space trajectories\n",
    "np.save(f\"{RESULTS_DIR}/latent_train.npy\", gru_outs_train_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_test.npy\", gru_outs_test_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_sindy_predict.npy\", x_predict)\n",
    "print(f\"Saved latent trajectories to {RESULTS_DIR}/latent_*.npy\")\n",
    "\n",
    "# Save SINDy model coefficients\n",
    "sindy_coefficients = model._model.coefficients()\n",
    "np.save(f\"{RESULTS_DIR}/sindy_coefficients.npy\", sindy_coefficients)\n",
    "print(f\"Saved SINDy coefficients to {RESULTS_DIR}/sindy_coefficients.npy\")\n",
    "print(f\"SINDy coefficients shape: {sindy_coefficients.shape}\")\n",
    "\n",
    "# Save SINDy feature names\n",
    "feature_names = model._model.get_feature_names()\n",
    "with open(f\"{RESULTS_DIR}/sindy_feature_names.txt\", \"w\") as f:\n",
    "    for name in feature_names:\n",
    "        f.write(name + \"\\n\")\n",
    "print(f\"Saved SINDy feature names to {RESULTS_DIR}/sindy_feature_names.txt\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    \"latent_dim\": latent_dim,\n",
    "    \"poly_order\": poly_order,\n",
    "    \"num_sensors\": num_sensors,\n",
    "    \"lags\": lags,\n",
    "    \"train_length\": train_length,\n",
    "    \"validate_length\": validate_length,\n",
    "    \"dt\": dt,\n",
    "    \"threshold\": threshold,\n",
    "    \"best_threshold\": best_threshold,\n",
    "    \"relative_error\": relative_error,\n",
    "}\n",
    "np.save(f\"{RESULTS_DIR}/config.npy\", config)\n",
    "print(f\"Saved configuration to {RESULTS_DIR}/config.npy\")\n",
    "\n",
    "# Save original data for reference\n",
    "np.save(f\"{RESULTS_DIR}/data_original.npy\", data_original)\n",
    "print(f\"Saved original data to {RESULTS_DIR}/data_original.npy\")\n",
    "\n",
    "# Print summary of saved files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saved files summary:\")\n",
    "print(\"=\"*50)\n",
    "for f in sorted(os.listdir(RESULTS_DIR)):\n",
    "    fpath = os.path.join(RESULTS_DIR, f)\n",
    "    size = os.path.getsize(fpath)\n",
    "    print(f\"  {f}: {size/1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87e597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
