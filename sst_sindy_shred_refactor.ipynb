{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-overview",
   "metadata": {},
   "source": [
    "# SINDy-SHRED Applied to Sea Surface Temperature Data\n",
    "\n",
    "This notebook demonstrates the SINDy-SHRED methodology applied to weekly mean sea-surface temperature (SST) data from the NOAA Optimum Interpolation SST V2 dataset.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**SHRED** (SHallow REcurrent Decoder) models combine a recurrent layer (LSTM/GRU) with a shallow decoder network to reconstruct high-dimensional spatio-temporal fields from sensor measurements.\n",
    "\n",
    "**SINDy-SHRED** extends this by integrating Sparse Identification of Nonlinear Dynamics (SINDy) to learn interpretable governing equations for the latent space dynamics:\n",
    "\n",
    "$$\\dot{z} = \\Theta(z) \\xi$$\n",
    "\n",
    "where $z$ is the latent space, $\\Theta(z)$ is a library of candidate functions, and $\\xi$ is a sparse coefficient matrix.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Data Loading\n",
    "3. Model Configuration and Training\n",
    "4. SINDy Discovery\n",
    "5. Evaluation and Visualization\n",
    "6. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Local modules\n",
    "from sindy_shred import SINDySHRED\n",
    "from processdata import load_data\n",
    "import plotting\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = \"results/sst\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-header",
   "metadata": {},
   "source": [
    "### Device Configuration\n",
    "\n",
    "Automatically select the best available compute device (CUDA, MPS, or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seed-header",
   "metadata": {},
   "source": [
    "### Random Seed\n",
    "\n",
    "Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the SST dataset and configure sensor locations and trajectory length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SST data\n",
    "load_X = load_data('SST')\n",
    "n = load_X.shape[0]  # Number of time samples\n",
    "m = load_X.shape[1]  # Spatial dimension\n",
    "\n",
    "print(f\"Data shape: {load_X.shape}\")\n",
    "print(f\"Number of time samples: {n}\")\n",
    "print(f\"Spatial dimension: {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "### Data and Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor configuration\n",
    "num_sensors = 250\n",
    "sensor_locations = np.random.choice(m, size=num_sensors, replace=False)\n",
    "\n",
    "# Trajectory length (52 weeks = 1 year of measurements)\n",
    "lags = 52\n",
    "\n",
    "# Data split\n",
    "train_length = 1000\n",
    "validate_length = 30\n",
    "\n",
    "# Time step (weekly data)\n",
    "dt = 1 / 52.0\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 3\n",
    "poly_order = 1\n",
    "\n",
    "# SINDy threshold for sparsity\n",
    "sindy_threshold = 0.05\n",
    "\n",
    "print(f\"Number of sensors: {num_sensors}\")\n",
    "print(f\"Trajectory length (lags): {lags}\")\n",
    "print(f\"Training length: {train_length}\")\n",
    "print(f\"Latent dimension: {latent_dim}\")\n",
    "print(f\"Polynomial order: {poly_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-data-header",
   "metadata": {},
   "source": [
    "### Visualize Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample sensor time series\n",
    "n_sensors_to_plot = min(num_sensors, 10)\n",
    "\n",
    "fig, axes = plt.subplots(n_sensors_to_plot, 1, figsize=(10, 2 * n_sensors_to_plot), sharex=True)\n",
    "for i in range(n_sensors_to_plot):\n",
    "    axes[i].plot(load_X[:, sensor_locations[i]])\n",
    "    axes[i].set_ylabel(f\"Sensor {i}\")\n",
    "axes[-1].set_xlabel(\"Time (weeks)\")\n",
    "fig.suptitle(\"Sample Sensor Time Series\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. Model Configuration and Training\n",
    "\n",
    "Initialize and train the SINDy-SHRED model using the `SINDySHRED` driver class.\n",
    "\n",
    "The driver handles:\n",
    "- Data preprocessing (scaling, train/val/test splits)\n",
    "- Model initialization\n",
    "- Training loop with SINDy regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SINDy-SHRED driver\n",
    "model = SINDySHRED(\n",
    "    latent_dim=latent_dim,\n",
    "    poly_order=poly_order,\n",
    "    include_sine=False,\n",
    "    ode_order=1,  # 1st order ODE: z' = f(z)\n",
    "    hidden_layers=2,\n",
    "    l1=350,\n",
    "    l2=400,\n",
    "    dropout=0.1,\n",
    "    batch_size=128,\n",
    "    num_epochs=200,\n",
    "    lr=1e-3,\n",
    "    verbose=True,\n",
    "    threshold=0.05,\n",
    "    patience=5,\n",
    "    sindy_regularization=10.0,\n",
    "    optimizer=\"AdamW\",\n",
    "    thres_epoch=100,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"SINDySHRED model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# The driver automatically handles data preprocessing and training\n",
    "model.fit(\n",
    "    num_sensors=num_sensors,\n",
    "    dt=dt,\n",
    "    x_to_fit=load_X,\n",
    "    lags=lags,\n",
    "    train_length=train_length,\n",
    "    validate_length=validate_length,\n",
    "    sensor_locations=sensor_locations,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sindy-header",
   "metadata": {},
   "source": [
    "## 4. SINDy Discovery\n",
    "\n",
    "Discover sparse governing equations from the learned latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-discover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SINDy identification on the latent space\n",
    "model.sindy_identify(threshold=sindy_threshold, plot_result=True)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"Latent Space: SINDy-SHRED vs Identified Model\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the latent comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved latent comparison plot to {RESULTS_DIR}/latent_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6qa7vmk7e8r",
   "metadata": {},
   "source": [
    "### Auto-Tune Threshold (Adaptive/Nonparametric)\n",
    "\n",
    "Alternatively, use `auto_tune_threshold()` to automatically determine the best threshold.\n",
    "By default it uses a nonparametric approach:\n",
    "1. First computes the least-squares solution (threshold=0)\n",
    "2. Uses `scale_factor * max(|coefficients|)` as the max threshold\n",
    "3. Tests `n_thresholds` evenly spaced values and picks the best stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7wwi2i5iab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-tune threshold using nonparametric approach\n",
    "# This computes least-squares solution first, then determines threshold range adaptively\n",
    "best_threshold, tune_results = model.auto_tune_threshold(\n",
    "    adaptive=True,           # Use nonparametric approach (default)\n",
    "    scale_factor=0.3,        # Max threshold = 0.3 * max(|coefficients|)\n",
    "    n_thresholds=10,         # Test 10 evenly spaced thresholds\n",
    "    metric=\"bic\", # Pick sparsest stable model\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.4f}\")\n",
    "print(f\"Tested thresholds: {tune_results['thresholds']}\")\n",
    "print(f\"Sparsity at each: {tune_results['sparsity']}\")\n",
    "print(f\"Stability at each: {tune_results['stable']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization\n",
    "\n",
    "Evaluate reconstruction performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recon-header",
   "metadata": {},
   "source": [
    "### Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test reconstruction error using new API\n",
    "test_recons = model.sensor_recon(data_type=\"test\", return_scaled=False)\n",
    "test_ground_truth = model._scaler.inverse_transform(\n",
    "    model._test_data.Y.detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "relative_error = model.relative_error(test_recons, test_ground_truth)\n",
    "print(f\"Test set relative reconstruction error: {relative_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sindy-predict-header",
   "metadata": {},
   "source": [
    "### SINDy Model Prediction\n",
    "\n",
    "Use the discovered SINDy model to predict latent trajectories and decode back to spatial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict latent trajectories using the discovered SINDy model\n",
    "x_predict = model.predict_latent()  # Alias for sindy_predict()\n",
    "\n",
    "# Decode SINDy predictions to spatial domain using new API\n",
    "output_sindy = model.decode_to_physical(x_predict)  # Alias for shred_decode()\n",
    "\n",
    "# Or use the convenience method:\n",
    "# output_sindy = model.forecast(init_from=\"test\", return_scaled=True)\n",
    "\n",
    "print(f\"SINDy prediction shape: {x_predict.shape}\")\n",
    "print(f\"Decoded output shape: {output_sindy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-header",
   "metadata": {},
   "source": [
    "### Spatial Reconstruction Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-sst-locs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SST location indices for visualization\n",
    "load_X_full = loadmat('Data/SST_data.mat')['Z'].T\n",
    "mean_X = np.mean(load_X_full, axis=0)\n",
    "sst_locs = np.where(mean_X != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare reconstructions at selected timesteps\n",
    "timesteps = [0, 50, 75, 100, 125]\n",
    "\n",
    "# Use the test data ground truth\n",
    "test_Y = model._test_data.Y.detach().cpu().numpy()\n",
    "\n",
    "fig, axes = plotting.plot_reconstruction_comparison(\n",
    "    test_Y,\n",
    "    output_sindy,\n",
    "    timesteps,\n",
    "    sst_locs=sst_locs,\n",
    "    lat_range=(0, 180),\n",
    "    lon_range=(0, 180),\n",
    "    diff_scale=10\n",
    ")\n",
    "fig.suptitle(\"Spatial Reconstruction: Real vs SINDy-Predicted\")\n",
    "\n",
    "# Save the spatial comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/spatial_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/spatial_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved spatial comparison plot to {RESULTS_DIR}/spatial_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensor-pred-header",
   "metadata": {},
   "source": [
    "### Sensor-Level Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensor-pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random sensor locations for visualization\n",
    "sensor_locations_viz = np.random.randint(1, 40000, size=18)\n",
    "sensor_indices = list(range(18))\n",
    "\n",
    "fig, axes = plotting.plot_sensor_predictions(\n",
    "    test_Y,\n",
    "    output_sindy,\n",
    "    sensor_locations=sensor_locations_viz,\n",
    "    sensor_indices=sensor_indices,\n",
    "    num_context=lags,  # Show context period before predictions\n",
    "    num_pred=min(250, len(output_sindy) - lags),\n",
    "    rows=3,\n",
    "    cols=6,\n",
    "    save_path=f\"{RESULTS_DIR}/sensor_predictions_grid.pdf\"\n",
    ")\n",
    "print(f\"Saved sensor predictions plot to {RESULTS_DIR}/sensor_predictions_grid.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latent-header",
   "metadata": {},
   "source": [
    "### Latent Space Analysis\n",
    "\n",
    "Visualize the latent space trajectories for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latent-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalized latent trajectories for test data\n",
    "gru_outs_test = model.gru_normalize(data_type=\"test\")\n",
    "gru_outs_test_np = gru_outs_test.detach().cpu().numpy()\n",
    "\n",
    "# Also get training latent trajectories\n",
    "gru_outs_train = model.gru_normalize(data_type=\"train\")\n",
    "gru_outs_train_np = gru_outs_train.detach().cpu().numpy()\n",
    "\n",
    "# Plot latent trajectories\n",
    "fig, axes = plt.subplots(latent_dim, 1, figsize=(10, 2 * latent_dim), sharex=True)\n",
    "for i in range(latent_dim):\n",
    "    axes[i].plot(gru_outs_test_np[:, i], label=f'Latent dim {i}')\n",
    "    axes[i].set_ylabel(f'$z_{i}$')\n",
    "    axes[i].legend(loc='upper right')\n",
    "axes[-1].set_xlabel('Time step')\n",
    "fig.suptitle('Test Set Latent Trajectories')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the latent trajectories plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_trajectories.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_trajectories.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved latent trajectories plot to {RESULTS_DIR}/latent_trajectories.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the SINDy-SHRED methodology on SST data using the `SINDySHRED` driver class:\n",
    "\n",
    "1. Loaded weekly SST data from NOAA\n",
    "2. Configured sensor locations and model hyperparameters\n",
    "3. Trained a SINDy-SHRED model using the driver interface\n",
    "4. Discovered sparse governing equations for the latent dynamics\n",
    "5. Evaluated reconstruction quality and visualized results\n",
    "6. **Saved all results** to the `results/sst/` folder\n",
    "\n",
    "### Saved Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `shred_model.pt` | Trained SHRED neural network weights |\n",
    "| `latent_train.npy` | Latent trajectories from training data |\n",
    "| `latent_test.npy` | Latent trajectories from test data |\n",
    "| `latent_sindy_predict.npy` | SINDy-predicted latent trajectories |\n",
    "| `sindy_coefficients.npy` | Learned SINDy coefficient matrix |\n",
    "| `sindy_feature_names.txt` | Names of SINDy library terms |\n",
    "| `config.npy` | Model configuration and hyperparameters |\n",
    "| `*.pdf/*.png` | Visualization plots |\n",
    "\n",
    "The `SINDySHRED` driver simplifies the workflow by handling:\n",
    "- Data preprocessing and scaling\n",
    "- Train/validation/test splits\n",
    "- Model initialization and training\n",
    "- Post-hoc SINDy identification\n",
    "- Latent space decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0vfh0hmwwj",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the trained model, latent space values, and learned SINDy model to the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcqba9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained SHRED model\n",
    "torch.save(model._shred.state_dict(), f\"{RESULTS_DIR}/shred_model.pt\")\n",
    "print(f\"Saved SHRED model to {RESULTS_DIR}/shred_model.pt\")\n",
    "\n",
    "# Save latent space trajectories\n",
    "np.save(f\"{RESULTS_DIR}/latent_train.npy\", gru_outs_train_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_test.npy\", gru_outs_test_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_sindy_predict.npy\", x_predict)\n",
    "print(f\"Saved latent trajectories to {RESULTS_DIR}/latent_*.npy\")\n",
    "\n",
    "# Save SINDy model coefficients\n",
    "sindy_coefficients = model._model.coefficients()\n",
    "np.save(f\"{RESULTS_DIR}/sindy_coefficients.npy\", sindy_coefficients)\n",
    "print(f\"Saved SINDy coefficients to {RESULTS_DIR}/sindy_coefficients.npy\")\n",
    "print(f\"SINDy coefficients shape: {sindy_coefficients.shape}\")\n",
    "\n",
    "# Save SINDy feature names\n",
    "feature_names = model._model.get_feature_names()\n",
    "with open(f\"{RESULTS_DIR}/sindy_feature_names.txt\", \"w\") as f:\n",
    "    for name in feature_names:\n",
    "        f.write(name + \"\\n\")\n",
    "print(f\"Saved SINDy feature names to {RESULTS_DIR}/sindy_feature_names.txt\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    \"latent_dim\": latent_dim,\n",
    "    \"poly_order\": poly_order,\n",
    "    \"num_sensors\": num_sensors,\n",
    "    \"lags\": lags,\n",
    "    \"train_length\": train_length,\n",
    "    \"validate_length\": validate_length,\n",
    "    \"dt\": dt,\n",
    "    \"sindy_threshold\": sindy_threshold,\n",
    "    \"relative_error\": relative_error,\n",
    "}\n",
    "np.save(f\"{RESULTS_DIR}/config.npy\", config)\n",
    "print(f\"Saved configuration to {RESULTS_DIR}/config.npy\")\n",
    "\n",
    "# Print summary of saved files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saved files summary:\")\n",
    "print(\"=\"*50)\n",
    "for f in sorted(os.listdir(RESULTS_DIR)):\n",
    "    fpath = os.path.join(RESULTS_DIR, f)\n",
    "    size = os.path.getsize(fpath)\n",
    "    print(f\"  {f}: {size/1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
