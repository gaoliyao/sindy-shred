{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalizing the SINDy-SHRED pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook gives an introductory walkthrough to using SHRED models.  The dataset we consider is weekly mean sea-surface temperature as given by the NOAA Optimum Interpolation SST V2 dataset (https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.html).\n",
    "\n",
    "SHRED (SHallow REcurrent Decoder) models are a network architecture that merges a recurrent layer (LSTM) with a shallow decoder network (SDN) to reconstruct high-dimensional spatio-temporal fields from a trajectory of sensor measurements of the field. More formally, the SHRED architecture can be written as \n",
    "$$ \\mathcal {H} \\left( \\{ y_i \\} _{i=t-k}^t \\right) = \\mathcal {F} \\left( \\mathcal {G} \\left( \\{ y_i \\} _{i=t-k}^t \\right) ; W_{RN}) ; W_{SD} \\right)$$\n",
    "where $\\mathcal F$ is a feed forward network parameterized by weights $W_{SD}$, $\\mathcal G$ is a LSTM network parameterized by weights $W_{RN}$, and $\\{ y_i \\} _{i=t-k}^t$ is a trajectory of sensor measurements of a high-dimensional spatio-temporal field $\\{ x_i \\} _{i=t-k}^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINDy-SHRED further extends the SHRED architecture by integrating **Sparse Identification of Nonlinear Dynamics (SINDy)** into the recurrent decoder framework. The key idea is to enforce a **parsimonious latent space representation**, where the dynamics of the latent variables are governed by a **sparse set of basis functions**. \n",
    "\n",
    "More formally, SINDy-SHRED introduces an additional inductive bias:\n",
    "\n",
    "$$\\dot{z} = \\Theta(z) \\xi$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $z = \\mathcal{G} \\left( \\{ y_i \\} _{i=t-k}^t \\right)$ represents the **latent space variables** extracted by the LSTM encoder.\n",
    "- $\\Theta(z)$ is a **library of candidate nonlinear functions**.\n",
    "- $\\xi$ is a **sparse coefficient matrix** that determines the governing equations.\n",
    "\n",
    "This combination enables **interpretable spatio-temporal modeling** by ensuring that the learned representations adhere to a **governing law**, making the method suitable for **data-driven discovery of dynamical systems** from high-dimensional, noisy observations.\n",
    "\n",
    "In this notebook, we will walk through the application of **SINDy-SHRED** on the **weekly mean sea-surface temperature (SST) dataset**, demonstrating how the model can **learn a reduced-order latent representation** and **recover the governing equations** that describe the SST evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first randomly select 3 sensor locations and set the trajectory length (lags) to 52, corresponding to one year of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysindy as ps\n",
    "\n",
    "# netcdf/numpy/xray/stats\n",
    "import scipy\n",
    "\n",
    "# import plotting\n",
    "import seaborn as sns\n",
    "import sindy\n",
    "import sindy_shred\n",
    "import driver as model_driver\n",
    "import torch\n",
    "from pysindy.differentiation import FiniteDifference\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(x_est, x_true):\n",
    "    \"\"\"Helper function for calculating the relative error.\n",
    "\n",
    "    :param x_est: Estimated values (i.e. from reconstruction)\n",
    "    :type x_est: numpy.ndarray\n",
    "    :param x_true: True (or observed) values.\n",
    "    :type x_true: numpy.ndarray\n",
    "    :return: Relative error between observations and model.\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(x_est - x_true) / np.linalg.norm(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolor_kwargs = {\n",
    "    \"vmin\": -3,\n",
    "    \"vmax\": 3,\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs_FNM(t, x, tau, a, b, Iext):\n",
    "    \"\"\"FitzHugh-Nagumo Model\n",
    "\n",
    "    See costs-tutorial_toy-data for details.\n",
    "    \"\"\"\n",
    "    v = x[0]\n",
    "    w = x[1]\n",
    "    vdot = v - (v**3) / 3 - w + Iext\n",
    "    wdot = (1 / tau) * (v + a - b * w)\n",
    "    dx = np.array([vdot, wdot])\n",
    "\n",
    "    return dx\n",
    "\n",
    "\n",
    "def rhs_UFD(t, y, eta, epsilon, tau):\n",
    "    \"\"\"Unforced Duffing Oscillator\n",
    "\n",
    "    See costs-tutorial_toy-data for details.\n",
    "    \"\"\"\n",
    "    p = y[0]\n",
    "    q = y[1]\n",
    "    pdot = q\n",
    "    qdot = (1 / tau) * (-2 * eta * q - p - epsilon * p**3)\n",
    "    dy = np.array([pdot, qdot])\n",
    "\n",
    "    return dy\n",
    "\n",
    "\n",
    "T = 64\n",
    "\n",
    "x0 = np.array([-1.110, -0.125])\n",
    "tau1 = 2\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "Iext = 0.65\n",
    "\n",
    "y0 = np.array([0, 1])\n",
    "eta = 0\n",
    "epsilon = 1\n",
    "tau2 = 0.2\n",
    "\n",
    "# RK4 integration of the mixed system\n",
    "dt = 0.0001 * 8\n",
    "t_solution = np.arange(0, T, dt)\n",
    "\n",
    "# Solve the FitzHugh-Nagumo Model\n",
    "solution_fn = solve_ivp(rhs_FNM, [0, T], x0, t_eval=t_solution, args=(tau1, a, b, Iext))\n",
    "\n",
    "# Solve the Unforced Duffing Oscillator Model\n",
    "solution_ufd = solve_ivp(\n",
    "    rhs_UFD, [0, T], y0, t_eval=t_solution, args=(eta, epsilon, tau2)\n",
    ")\n",
    "\n",
    "seed = 1\n",
    "num_space_dims = 10\n",
    "\n",
    "uv_tiled = np.hstack(\n",
    "    [\n",
    "        np.tile(solution_fn.y.T, num_space_dims),\n",
    "        np.tile(solution_ufd.y.T, num_space_dims),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Subsample after solving the pdes\n",
    "substep = 50\n",
    "uv_tiled = uv_tiled[0::substep, :]\n",
    "t_solution = t_solution[0::substep]\n",
    "time = t_solution\n",
    "dt = time[1] - time[0]\n",
    "dt_data = np.copy(dt)\n",
    "\n",
    "# Dimension of space to map into\n",
    "n_space_dims = np.shape(uv_tiled)[1]\n",
    "n_time = np.shape(uv_tiled)[0]\n",
    "\n",
    "# Orthonormalized linear mixing matrix\n",
    "Q = scipy.stats.ortho_group.rvs(n_space_dims, random_state=seed)\n",
    "Q = Q[0:n_space_dims, :]\n",
    "x = uv_tiled @ Q\n",
    "\n",
    "# COSTS expects time by space, so we transpose x.\n",
    "data_original = x.T\n",
    "\n",
    "# For the scale separation we want to compare to the actual slow and fast\n",
    "# components.\n",
    "slow_modes = uv_tiled[:, 0 : n_space_dims // 2] @ Q[0 : n_space_dims // 2, :]\n",
    "fast_modes = uv_tiled[:, n_space_dims // 2 :] @ Q[n_space_dims // 2 :, :]\n",
    "\n",
    "space_dim = np.arange(n_space_dims)\n",
    "xgrid, tgrid = np.meshgrid(space_dim, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6, 5), sharex=True, sharey=True)\n",
    "\n",
    "pcolor_kwargs = {\n",
    "    \"vmin\": -3,\n",
    "    \"vmax\": 3,\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "    \"rasterized\": True,\n",
    "}\n",
    "\n",
    "# Original data\n",
    "ax = axes[0]\n",
    "ax.pcolor(time, space_dim, data_original, **pcolor_kwargs)\n",
    "ax.set_title(r\"a) $\\mathbf{x}_{total}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"space (-)\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolor(time, space_dim, slow_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"b) $\\mathbf{x}_{slow}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"space (-)\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.pcolor(time, space_dim, fast_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"c) $\\mathbf{x}_{fast}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"space (-)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINDy-SHRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this BEFORE importing torch if you need to control GPU access\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Choose device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Optional: CUDA-specific seed (only if using CUDA)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(0)\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now select indices to divide the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove randomness for investigation\n",
    "sensor_locations = np.array([10, 28, 14, 11, 23, 27])\n",
    "num_sensors = len(sensor_locations)\n",
    "\n",
    "# Threshold for identifying sparse dynamics in SINDy\n",
    "threshold = 0.0\n",
    "\n",
    "latent_dim = 4\n",
    "poly_order = 1\n",
    "include_sine = False\n",
    "# This is required to be True as it is baked into the code at the moment.\n",
    "include_constant = True\n",
    "library_dim = sindy.library_size(latent_dim, poly_order, include_sine, include_constant)\n",
    "\n",
    "lags = 120\n",
    "train_length = 750 // 4\n",
    "validate_length = 0\n",
    "load_X = copy.deepcopy(data_original)\n",
    "\n",
    "# Sub-sample for speed up\n",
    "load_X = load_X.T[::4]\n",
    "dt = dt_data * 4\n",
    "lags = lags // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(load_X[:, sensor_locations], color='b')\n",
    "plt.gca().axvline(train_length, color='k')\n",
    "plt.gca().axvline(lags, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit SINDy-SHRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = model_driver.sindy_shred_driver(latent_dim=latent_dim, poly_order=poly_order, verbose=True)\n",
    "driver.fit(\n",
    "    num_sensors,\n",
    "    dt,\n",
    "    load_X,\n",
    "    lags,\n",
    "    train_length,\n",
    "    validate_length,\n",
    "    sensor_locations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posthoc dynamics discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.sindy_identify(threshold=threshold, plot_result=True, )\n",
    "plt.gcf().suptitle(f\"latent space\")\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slow modes are:\n",
    "\\begin{align}\\label{eq:slow-mode}\n",
    "    \\dot{v}& = v - \\frac{1}{3}v^3 - w + 0.65 \\\\\n",
    "    \\dot{w} &= \\frac{1}{\\tau_1}(v + 0.7 - 0.8w).\n",
    "\\end{align}\n",
    "\n",
    "and the fast modes are:\n",
    "\\begin{align}\\label{eq:fast-mode}\n",
    "    \\dot{p}& = q \\\\\n",
    "    \\dot{q}& = -\\frac{1}{\\tau_2}(p + p^3).\n",
    "\\end{align}\n",
    "\n",
    "with the time constants of $\\tau_1= 2$ for the slow mode and $\\tau_2=0.2$ for the fast mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recons = driver._scaler.inverse_transform(\n",
    "    driver._shred(driver._test_data.X).detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "test_ground_truth = driver._scaler.inverse_transform(\n",
    "    driver._test_data.Y.detach().cpu().numpy()\n",
    ")\n",
    "print(\n",
    "    np.linalg.norm(test_recons - test_ground_truth) / np.linalg.norm(test_ground_truth)\n",
    ")\n",
    "\n",
    "test_recons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.pcolormesh(test_recons, **pcolor_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
