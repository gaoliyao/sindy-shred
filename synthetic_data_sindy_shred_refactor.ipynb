{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-overview",
   "metadata": {},
   "source": [
    "gi# SINDy-SHRED: Toy Data Example\n",
    "\n",
    "This notebook demonstrates SINDy-SHRED on a synthetic toy dataset using the `SINDySHRED` class. The class handles data preprocessing, model training, and post-hoc SINDy discovery automatically.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**SHRED** (SHallow REcurrent Decoder) models combine a recurrent layer (GRU) with a shallow decoder network to reconstruct high-dimensional spatio-temporal fields from sensor measurements.\n",
    "\n",
    "**SINDy-SHRED** extends this by integrating Sparse Identification of Nonlinear Dynamics (SINDy) to learn interpretable governing equations:\n",
    "\n",
    "$$\\dot{z} = \\Theta(z) \\xi$$\n",
    "\n",
    "## Toy Data\n",
    "\n",
    "The synthetic data combines two dynamical systems:\n",
    "\n",
    "1. **FitzHugh-Nagumo Model** (slow dynamics):\n",
    "   $$\\dot{v} = v - \\frac{1}{3}v^3 - w + I_{ext}$$\n",
    "   $$\\dot{w} = \\frac{1}{\\tau_1}(v + a - bw)$$\n",
    "\n",
    "2. **Unforced Duffing Oscillator** (fast dynamics):\n",
    "   $$\\dot{p} = q$$\n",
    "   $$\\dot{q} = -\\frac{1}{\\tau_2}(p + \\epsilon p^3)$$\n",
    "\n",
    "These are combined via orthogonal mixing to create multi-scale spatio-temporal data.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Data Generation\n",
    "3. Model Configuration and Training\n",
    "4. SINDy Discovery\n",
    "5. Evaluation\n",
    "6. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Local modules\n",
    "from sindy_shred import SINDySHRED\n",
    "import plotting\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = \"results/toy_data\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-header",
   "metadata": {},
   "source": [
    "### Device and Seed Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-config",
   "metadata": {},
   "source": [
    "### Plotting Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pcolor_kwargs = {\n",
    "    \"vmin\": -3,\n",
    "    \"vmax\": 3,\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "    \"rasterized\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "Generate synthetic spatio-temporal data from the FitzHugh-Nagumo and Duffing oscillator systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamics-header",
   "metadata": {},
   "source": [
    "### Define Dynamical Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamics-def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs_FNM(t, x, tau, a, b, Iext):\n",
    "    \"\"\"FitzHugh-Nagumo Model (slow dynamics).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t : float\n",
    "        Time (unused, for ODE solver interface).\n",
    "    x : array-like\n",
    "        State vector [v, w].\n",
    "    tau : float\n",
    "        Time constant.\n",
    "    a, b : float\n",
    "        Model parameters.\n",
    "    Iext : float\n",
    "        External input current.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dx : array-like\n",
    "        Time derivatives [dv/dt, dw/dt].\n",
    "    \"\"\"\n",
    "    v, w = x\n",
    "    vdot = v - (v**3) / 3 - w + Iext\n",
    "    wdot = (1 / tau) * (v + a - b * w)\n",
    "    return np.array([vdot, wdot])\n",
    "\n",
    "\n",
    "def rhs_UFD(t, y, eta, epsilon, tau):\n",
    "    \"\"\"Unforced Duffing Oscillator (fast dynamics).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t : float\n",
    "        Time (unused, for ODE solver interface).\n",
    "    y : array-like\n",
    "        State vector [p, q].\n",
    "    eta : float\n",
    "        Damping coefficient.\n",
    "    epsilon : float\n",
    "        Nonlinearity strength.\n",
    "    tau : float\n",
    "        Time constant.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dy : array-like\n",
    "        Time derivatives [dp/dt, dq/dt].\n",
    "    \"\"\"\n",
    "    p, q = y\n",
    "    pdot = q\n",
    "    qdot = (1 / tau) * (-2 * eta * q - p - epsilon * p**3)\n",
    "    return np.array([pdot, qdot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-header",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time integration parameters\n",
    "T = 64\n",
    "dt = 0.0001 * 8\n",
    "t_solution = np.arange(0, T, dt)\n",
    "\n",
    "# FitzHugh-Nagumo parameters (slow mode, tau1=2)\n",
    "x0 = np.array([-1.110, -0.125])\n",
    "tau1 = 2\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "Iext = 0.65\n",
    "\n",
    "# Duffing oscillator parameters (fast mode, tau2=0.2)\n",
    "y0 = np.array([0, 1])\n",
    "eta = 0\n",
    "epsilon = 1\n",
    "tau2 = 0.2\n",
    "\n",
    "# Solve the ODEs\n",
    "solution_fn = solve_ivp(\n",
    "    rhs_FNM, [0, T], x0, t_eval=t_solution, args=(tau1, a, b, Iext)\n",
    ")\n",
    "solution_ufd = solve_ivp(\n",
    "    rhs_UFD, [0, T], y0, t_eval=t_solution, args=(eta, epsilon, tau2)\n",
    ")\n",
    "\n",
    "print(f\"FitzHugh-Nagumo solution shape: {solution_fn.y.shape}\")\n",
    "print(f\"Duffing oscillator solution shape: {solution_ufd.y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mix-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mixed spatio-temporal data\n",
    "seed = 1\n",
    "num_space_dims = 10\n",
    "\n",
    "# Tile the solutions to create spatial replicates\n",
    "uv_tiled = np.hstack([\n",
    "    np.tile(solution_fn.y.T, num_space_dims),\n",
    "    np.tile(solution_ufd.y.T, num_space_dims),\n",
    "])\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "substep = 50\n",
    "uv_tiled = uv_tiled[0::substep, :]\n",
    "t_solution = t_solution[0::substep]\n",
    "time = t_solution\n",
    "dt_data = time[1] - time[0]\n",
    "\n",
    "# Get dimensions\n",
    "n_space_dims = uv_tiled.shape[1]\n",
    "n_time = uv_tiled.shape[0]\n",
    "\n",
    "# Apply orthogonal mixing\n",
    "Q = scipy.stats.ortho_group.rvs(n_space_dims, random_state=seed)\n",
    "Q = Q[0:n_space_dims, :]\n",
    "x = uv_tiled @ Q\n",
    "\n",
    "# Final data matrix (time x space)\n",
    "data_original = x.T\n",
    "\n",
    "# Extract slow and fast mode components for comparison\n",
    "slow_modes = uv_tiled[:, 0:n_space_dims // 2] @ Q[0:n_space_dims // 2, :]\n",
    "fast_modes = uv_tiled[:, n_space_dims // 2:] @ Q[n_space_dims // 2:, :]\n",
    "\n",
    "print(f\"Data shape (space x time): {data_original.shape}\")\n",
    "print(f\"Time step: {dt_data:.6f}\")\n",
    "print(f\"Number of time samples: {n_time}\")\n",
    "print(f\"Spatial dimension: {n_space_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-data-header",
   "metadata": {},
   "source": [
    "### Visualize Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dim = np.arange(n_space_dims)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.pcolormesh(time, space_dim, data_original, **pcolor_kwargs)\n",
    "ax.set_title(r\"a) Total signal $\\mathbf{x}_{total}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolormesh(time, space_dim, slow_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"b) Slow component $\\mathbf{x}_{slow}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.pcolormesh(time, space_dim, fast_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"c) Fast component $\\mathbf{x}_{fast}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the data visualization plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/data_components.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/data_components.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved data components plot to {RESULTS_DIR}/data_components.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. Model Configuration and Training\n",
    "\n",
    "Configure the SINDy-SHRED model using the `SINDyShred` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "### Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor configuration (fixed for reproducibility)\n",
    "sensor_locations = np.array([10, 28, 14, 11, 23, 27])\n",
    "num_sensors = len(sensor_locations)\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 4\n",
    "poly_order = 1\n",
    "include_sine = False\n",
    "include_constant = True\n",
    "\n",
    "# Data split configuration\n",
    "lags = 120\n",
    "train_length = 750 // 4\n",
    "validate_length = 0\n",
    "\n",
    "# Prepare data (transpose to time x space, subsample)\n",
    "load_X = copy.deepcopy(data_original)\n",
    "load_X = load_X.T[::4]  # Subsample\n",
    "dt = dt_data * 4\n",
    "lags = lags // 4\n",
    "\n",
    "# SINDy threshold\n",
    "threshold = 0.0\n",
    "\n",
    "print(f\"Data shape after preprocessing: {load_X.shape}\")\n",
    "print(f\"Number of sensors: {num_sensors}\")\n",
    "print(f\"Latent dimension: {latent_dim}\")\n",
    "print(f\"Trajectory length (lags): {lags}\")\n",
    "print(f\"Training length: {train_length}\")\n",
    "print(f\"Time step: {dt:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor time series\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(load_X[:, sensor_locations], color='b', alpha=0.7)\n",
    "ax.axvline(train_length, color='k', linestyle='--', label='Train/Test split')\n",
    "ax.axvline(lags, color='r', linestyle=':', label='Lag window')\n",
    "ax.set_xlabel('Time step')\n",
    "ax.set_ylabel('Sensor value')\n",
    "ax.set_title('Sensor Time Series')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "### Initialize and Train Model\n",
    "\n",
    "The `SINDySHRED` class handles data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SINDySHRED(\n",
    "    latent_dim=latent_dim, \n",
    "    poly_order=poly_order,\n",
    "    ode_order=1,  # 1st order ODE: z' = f(z)\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    num_sensors,\n",
    "    dt,\n",
    "    load_X,\n",
    "    lags,\n",
    "    train_length,\n",
    "    validate_length,\n",
    "    sensor_locations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sindy-header",
   "metadata": {},
   "source": [
    "## 4. SINDy Discovery\n",
    "\n",
    "Discover sparse governing equations from the learned latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-discover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SINDy identification\n",
    "model.sindy_identify(threshold=threshold, plot_result=True)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"Latent Space: SINDy-SHRED vs Identified Model\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the latent comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved latent comparison plot to {RESULTS_DIR}/latent_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ko8yf9wgy",
   "metadata": {},
   "source": [
    "### Auto-Tune Threshold (Adaptive/Nonparametric)\n",
    "\n",
    "Alternatively, use `auto_tune_threshold()` to automatically determine the best threshold.\n",
    "By default it uses a nonparametric approach:\n",
    "1. First computes the least-squares solution (threshold=0)\n",
    "2. Uses `scale_factor * max(|coefficients|)` as the max threshold\n",
    "3. Tests `n_thresholds` evenly spaced values and picks the best stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcn2gi3cbgj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-tune threshold using nonparametric approach\n",
    "# This computes least-squares solution first, then determines threshold range adaptively\n",
    "best_threshold, tune_results = model.auto_tune_threshold(\n",
    "    adaptive=True,           # Use nonparametric approach (default)\n",
    "    scale_factor=0.3,        # Max threshold = 0.3 * max(|coefficients|)\n",
    "    n_thresholds=10,         # Test 10 evenly spaced thresholds\n",
    "    metric=\"bic\", # Pick sparsest stable model\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.4f}\")\n",
    "print(f\"Tested thresholds: {tune_results['thresholds']}\")\n",
    "print(f\"Sparsity at each: {tune_results['sparsity']}\")\n",
    "print(f\"Stability at each: {tune_results['stable']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "true-eqns-header",
   "metadata": {},
   "source": [
    "### True Governing Equations\n",
    "\n",
    "For reference, the true governing equations are:\n",
    "\n",
    "**Slow modes (FitzHugh-Nagumo):**\n",
    "$$\\dot{v} = v - \\frac{1}{3}v^3 - w + 0.65$$\n",
    "$$\\dot{w} = \\frac{1}{\\tau_1}(v + 0.7 - 0.8w)$$\n",
    "\n",
    "with time constant $\\tau_1 = 2$.\n",
    "\n",
    "**Fast modes (Duffing):**\n",
    "$$\\dot{p} = q$$\n",
    "$$\\dot{q} = -\\frac{1}{\\tau_2}(p + p^3)$$\n",
    "\n",
    "with time constant $\\tau_2 = 0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate reconstruction performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test reconstruction error using new API\n",
    "test_recons = model.sensor_recon(data_type=\"test\", return_scaled=False)\n",
    "test_ground_truth = model._scaler.inverse_transform(\n",
    "    model._test_data.Y.detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "relative_error = model.relative_error(test_recons, test_ground_truth)\n",
    "print(f\"Test set relative reconstruction error: {relative_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.pcolormesh(test_ground_truth.T, **pcolor_kwargs)\n",
    "ax.set_title(\"Ground Truth\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolormesh(test_recons.T, **pcolor_kwargs)\n",
    "ax.set_title(\"SINDy-SHRED Reconstruction\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time step\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the reconstruction comparison plot\n",
    "fig.savefig(f\"{RESULTS_DIR}/reconstruction_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(f\"{RESULTS_DIR}/reconstruction_comparison.png\", bbox_inches=\"tight\", dpi=300)\n",
    "print(f\"Saved reconstruction comparison plot to {RESULTS_DIR}/reconstruction_comparison.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qmfogl9s07j",
   "metadata": {},
   "source": [
    "### Sensor-Level Predictions\n",
    "\n",
    "Compare real vs predicted at individual spatial locations (sensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7j9hs76chc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor-level comparisons (all 10 spatial dimensions)\n",
    "fig, axes = plotting.plot_sensor_predictions(\n",
    "    test_ground_truth,\n",
    "    test_recons,\n",
    "    sensor_locations=np.arange(n_space_dims),  # All spatial dims\n",
    "    rows=2,\n",
    "    cols=5,\n",
    "    save_path=f\"{RESULTS_DIR}/sensor_predictions_grid.pdf\"\n",
    ")\n",
    "fig.suptitle(\"Sensor-Level Predictions: Real vs Reconstructed\")\n",
    "fig.tight_layout()\n",
    "print(f\"Saved sensor predictions plot to {RESULTS_DIR}/sensor_predictions_grid.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated SINDy-SHRED on synthetic multi-scale data:\n",
    "\n",
    "1. Generated toy data from FitzHugh-Nagumo (slow) and Duffing (fast) oscillators\n",
    "2. Used the `SINDySHRED` class for streamlined model training\n",
    "3. Discovered sparse governing equations that approximate the true dynamics\n",
    "4. Achieved accurate reconstruction on held-out test data\n",
    "5. **Saved all results** to the `results/toy_data/` folder\n",
    "\n",
    "### Saved Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `shred_model.pt` | Trained SHRED neural network weights |\n",
    "| `latent_train.npy` | Latent trajectories from training data |\n",
    "| `latent_test.npy` | Latent trajectories from test data |\n",
    "| `latent_sindy_predict.npy` | SINDy-predicted latent trajectories |\n",
    "| `sindy_coefficients.npy` | Learned SINDy coefficient matrix |\n",
    "| `sindy_feature_names.txt` | Names of SINDy library terms |\n",
    "| `config.npy` | Model configuration and hyperparameters |\n",
    "| `data_original.npy` | Original mixed spatio-temporal data |\n",
    "| `slow_modes.npy` | FitzHugh-Nagumo slow component |\n",
    "| `fast_modes.npy` | Duffing oscillator fast component |\n",
    "| `*.pdf/*.png` | Visualization plots |\n",
    "\n",
    "The `SINDySHRED` class simplifies the workflow compared to manual data preprocessing and model setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fxb4e8lpmrm",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the trained model, latent space values, and learned SINDy model to the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1taarlk6mj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latent space trajectories\n",
    "gru_outs_train = model.gru_normalize(data_type=\"train\")\n",
    "gru_outs_train_np = gru_outs_train.detach().cpu().numpy()\n",
    "\n",
    "gru_outs_test = model.gru_normalize(data_type=\"test\")\n",
    "gru_outs_test_np = gru_outs_test.detach().cpu().numpy()\n",
    "\n",
    "# Get SINDy predictions\n",
    "x_predict = model.predict_latent()\n",
    "\n",
    "# Save the trained SHRED model\n",
    "torch.save(model._shred.state_dict(), f\"{RESULTS_DIR}/shred_model.pt\")\n",
    "print(f\"Saved SHRED model to {RESULTS_DIR}/shred_model.pt\")\n",
    "\n",
    "# Save latent space trajectories\n",
    "np.save(f\"{RESULTS_DIR}/latent_train.npy\", gru_outs_train_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_test.npy\", gru_outs_test_np)\n",
    "np.save(f\"{RESULTS_DIR}/latent_sindy_predict.npy\", x_predict)\n",
    "print(f\"Saved latent trajectories to {RESULTS_DIR}/latent_*.npy\")\n",
    "\n",
    "# Save SINDy model coefficients\n",
    "sindy_coefficients = model._model.coefficients()\n",
    "np.save(f\"{RESULTS_DIR}/sindy_coefficients.npy\", sindy_coefficients)\n",
    "print(f\"Saved SINDy coefficients to {RESULTS_DIR}/sindy_coefficients.npy\")\n",
    "print(f\"SINDy coefficients shape: {sindy_coefficients.shape}\")\n",
    "\n",
    "# Save SINDy feature names\n",
    "feature_names = model._model.get_feature_names()\n",
    "with open(f\"{RESULTS_DIR}/sindy_feature_names.txt\", \"w\") as f:\n",
    "    for name in feature_names:\n",
    "        f.write(name + \"\\n\")\n",
    "print(f\"Saved SINDy feature names to {RESULTS_DIR}/sindy_feature_names.txt\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    \"latent_dim\": latent_dim,\n",
    "    \"poly_order\": poly_order,\n",
    "    \"num_sensors\": num_sensors,\n",
    "    \"lags\": lags,\n",
    "    \"train_length\": train_length,\n",
    "    \"validate_length\": validate_length,\n",
    "    \"dt\": dt,\n",
    "    \"threshold\": threshold,\n",
    "    \"relative_error\": relative_error,\n",
    "}\n",
    "np.save(f\"{RESULTS_DIR}/config.npy\", config)\n",
    "print(f\"Saved configuration to {RESULTS_DIR}/config.npy\")\n",
    "\n",
    "# Save original data for reference\n",
    "np.save(f\"{RESULTS_DIR}/data_original.npy\", data_original)\n",
    "np.save(f\"{RESULTS_DIR}/slow_modes.npy\", slow_modes)\n",
    "np.save(f\"{RESULTS_DIR}/fast_modes.npy\", fast_modes)\n",
    "print(f\"Saved original data components to {RESULTS_DIR}/\")\n",
    "\n",
    "# Print summary of saved files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saved files summary:\")\n",
    "print(\"=\"*50)\n",
    "for f in sorted(os.listdir(RESULTS_DIR)):\n",
    "    fpath = os.path.join(RESULTS_DIR, f)\n",
    "    size = os.path.getsize(fpath)\n",
    "    print(f\"  {f}: {size/1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
