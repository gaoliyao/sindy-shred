{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {},
   "source": [
    "# SINDy-SHRED: Toy Data Example (Low-Level API)\n",
    "\n",
    "This notebook demonstrates the detailed workflow of SINDy-SHRED on synthetic toy data.\n",
    "For a simpler high-level interface, see `sindy-shred_functionalized.toy-data.v2_refactor.ipynb`.\n",
    "\n",
    "**Toy Data:** Combines two dynamical systems:\n",
    "1. **FitzHugh-Nagumo Model** (slow dynamics)\n",
    "2. **Unforced Duffing Oscillator** (fast dynamics)\n",
    "\n",
    "These are combined via orthogonal mixing to create multi-scale spatio-temporal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pysindy as ps\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Local modules\n",
    "import sindy\n",
    "import sindy_shred_net\n",
    "import plotting\n",
    "from utils import get_device, TimeSeriesDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = \"results/toy_data\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting configuration\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pcolor_kwargs = {\n",
    "    \"vmin\": -3,\n",
    "    \"vmax\": 3,\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "    \"rasterized\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-header",
   "metadata": {},
   "source": [
    "### Device and Seed Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "Generate synthetic spatio-temporal data from FitzHugh-Nagumo and Duffing oscillator systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamics-def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs_FNM(t, x, tau, a, b, Iext):\n",
    "    \"\"\"FitzHugh-Nagumo Model (slow dynamics).\"\"\"\n",
    "    v, w = x\n",
    "    vdot = v - (v**3) / 3 - w + Iext\n",
    "    wdot = (1 / tau) * (v + a - b * w)\n",
    "    return np.array([vdot, wdot])\n",
    "\n",
    "\n",
    "def rhs_UFD(t, y, eta, epsilon, tau):\n",
    "    \"\"\"Unforced Duffing Oscillator (fast dynamics).\"\"\"\n",
    "    p, q = y\n",
    "    pdot = q\n",
    "    qdot = (1 / tau) * (-2 * eta * q - p - epsilon * p**3)\n",
    "    return np.array([pdot, qdot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time integration parameters\n",
    "T = 64\n",
    "dt_solve = 0.0001 * 8\n",
    "t_solution = np.arange(0, T, dt_solve)\n",
    "\n",
    "# FitzHugh-Nagumo parameters (slow mode, tau1=2)\n",
    "x0 = np.array([-1.110, -0.125])\n",
    "tau1 = 2\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "Iext = 0.65\n",
    "\n",
    "# Duffing oscillator parameters (fast mode, tau2=0.2)\n",
    "y0 = np.array([0, 1])\n",
    "eta = 0\n",
    "epsilon = 1\n",
    "tau2 = 0.2\n",
    "\n",
    "# Solve the ODEs\n",
    "solution_fn = solve_ivp(\n",
    "    rhs_FNM, [0, T], x0, t_eval=t_solution, args=(tau1, a, b, Iext)\n",
    ")\n",
    "solution_ufd = solve_ivp(\n",
    "    rhs_UFD, [0, T], y0, t_eval=t_solution, args=(eta, epsilon, tau2)\n",
    ")\n",
    "\n",
    "print(f\"FitzHugh-Nagumo solution shape: {solution_fn.y.shape}\")\n",
    "print(f\"Duffing oscillator solution shape: {solution_ufd.y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mix-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mixed spatio-temporal data\n",
    "seed = 1\n",
    "num_space_dims = 10\n",
    "\n",
    "# Tile the solutions to create spatial replicates\n",
    "uv_tiled = np.hstack([\n",
    "    np.tile(solution_fn.y.T, num_space_dims),\n",
    "    np.tile(solution_ufd.y.T, num_space_dims),\n",
    "])\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "substep = 50\n",
    "uv_tiled = uv_tiled[0::substep, :]\n",
    "t_solution = t_solution[0::substep]\n",
    "time = t_solution\n",
    "dt_data = time[1] - time[0]\n",
    "\n",
    "# Get dimensions\n",
    "n_space_dims = uv_tiled.shape[1]\n",
    "n_time = uv_tiled.shape[0]\n",
    "\n",
    "# Apply orthogonal mixing\n",
    "Q = scipy.stats.ortho_group.rvs(n_space_dims, random_state=seed)\n",
    "Q = Q[0:n_space_dims, :]\n",
    "x = uv_tiled @ Q\n",
    "\n",
    "# Final data matrix (space x time for visualization, time x space for processing)\n",
    "data_original = x.T\n",
    "\n",
    "# Extract slow and fast mode components for comparison\n",
    "slow_modes = uv_tiled[:, 0:n_space_dims // 2] @ Q[0:n_space_dims // 2, :]\n",
    "fast_modes = uv_tiled[:, n_space_dims // 2:] @ Q[n_space_dims // 2:, :]\n",
    "\n",
    "print(f\"Data shape (space x time): {data_original.shape}\")\n",
    "print(f\"Time step: {dt_data:.6f}\")\n",
    "print(f\"Number of time samples: {n_time}\")\n",
    "print(f\"Spatial dimension: {n_space_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated data\n",
    "space_dim = np.arange(n_space_dims)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.pcolormesh(time, space_dim, data_original, **pcolor_kwargs)\n",
    "ax.set_title(r\"a) Total signal $\\mathbf{x}_{total}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolormesh(time, space_dim, slow_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"b) Slow component $\\mathbf{x}_{slow}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.pcolormesh(time, space_dim, fast_modes.T, **pcolor_kwargs)\n",
    "ax.set_title(r\"c) Fast component $\\mathbf{x}_{fast}$\", loc=\"left\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{RESULTS_DIR}/data_components.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 3. Configuration and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor configuration (fixed for reproducibility)\n",
    "sensor_locations = np.array([10, 28, 14, 11, 23, 27])\n",
    "num_sensors = len(sensor_locations)\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 4\n",
    "poly_order = 1\n",
    "include_sine = False\n",
    "\n",
    "# Calculate library dimension\n",
    "library_dim = sindy.library_size(latent_dim, poly_order, include_sine, include_constant=True)\n",
    "\n",
    "# Data split configuration\n",
    "lags = 120\n",
    "train_length = 750 // 4\n",
    "validate_length = 0\n",
    "\n",
    "# Prepare data (transpose to time x space, subsample)\n",
    "load_X = copy.deepcopy(data_original)\n",
    "load_X = load_X.T[::4]  # Subsample by 4\n",
    "dt = dt_data * 4\n",
    "lags = lags // 4\n",
    "\n",
    "n = load_X.shape[0]\n",
    "m = load_X.shape[1]\n",
    "\n",
    "# SINDy threshold\n",
    "sindy_threshold = 0.0\n",
    "\n",
    "print(f\"Data shape after preprocessing: {load_X.shape}\")\n",
    "print(f\"Number of sensors: {num_sensors}\")\n",
    "print(f\"Latent dimension: {latent_dim}\")\n",
    "print(f\"Library dimension: {library_dim}\")\n",
    "print(f\"Trajectory length (lags): {lags}\")\n",
    "print(f\"Training length: {train_length}\")\n",
    "print(f\"Time step: {dt:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor time series\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(load_X[:, sensor_locations], color='b', alpha=0.7)\n",
    "ax.axvline(train_length, color='k', linestyle='--', label='Train/Test split')\n",
    "ax.axvline(lags, color='r', linestyle=':', label='Lag window')\n",
    "ax.set_xlabel('Time step')\n",
    "ax.set_ylabel('Sensor value')\n",
    "ax.set_title('Sensor Time Series')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test indices\n",
    "train_indices = np.arange(0, train_length)\n",
    "\n",
    "mask = np.ones(n - lags)\n",
    "mask[train_indices] = 0\n",
    "test_indices = np.arange(0, n - lags)[np.where(mask != 0)[0]]\n",
    "\n",
    "# For this example, validation = empty\n",
    "valid_indices = test_indices[:validate_length] if validate_length > 0 else train_indices[:1]\n",
    "\n",
    "print(f\"Train samples: {len(train_indices)}\")\n",
    "print(f\"Test samples: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "sc = sc.fit(load_X[train_indices])\n",
    "transformed_X = sc.transform(load_X)\n",
    "\n",
    "# Generate input sequences (sensor trajectories)\n",
    "all_data_in = np.zeros((n - lags, lags, num_sensors))\n",
    "for i in range(len(all_data_in)):\n",
    "    all_data_in[i] = transformed_X[i:i+lags, sensor_locations]\n",
    "\n",
    "# Create input/output tensors\n",
    "train_data_in = torch.tensor(all_data_in[train_indices], dtype=torch.float32).to(device)\n",
    "valid_data_in = torch.tensor(all_data_in[valid_indices], dtype=torch.float32).to(device)\n",
    "test_data_in = torch.tensor(all_data_in[test_indices], dtype=torch.float32).to(device)\n",
    "\n",
    "train_data_out = torch.tensor(transformed_X[train_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "valid_data_out = torch.tensor(transformed_X[valid_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "test_data_out = torch.tensor(transformed_X[test_indices + lags - 1], dtype=torch.float32).to(device)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(train_data_in, train_data_out)\n",
    "valid_dataset = TimeSeriesDataset(valid_data_in, valid_data_out)\n",
    "test_dataset = TimeSeriesDataset(test_data_in, test_data_out)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 4. Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SINDy-SHRED network\n",
    "shred = sindy_shred_net.SINDy_SHRED_net(\n",
    "    input_size=num_sensors,\n",
    "    output_size=m,\n",
    "    hidden_size=latent_dim,\n",
    "    hidden_layers=2,\n",
    "    l1=350,\n",
    "    l2=400,\n",
    "    dropout=0.1,\n",
    "    library_dim=library_dim,\n",
    "    poly_order=poly_order,\n",
    "    include_sine=include_sine,\n",
    "    dt=dt,\n",
    ").to(device)\n",
    "\n",
    "print(\"SINDy-SHRED network created\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in shred.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "validation_errors = sindy_shred_net.fit(\n",
    "    shred,\n",
    "    train_dataset,\n",
    "    valid_dataset,\n",
    "    batch_size=64,\n",
    "    num_epochs=200,\n",
    "    lr=1e-3,\n",
    "    verbose=True,\n",
    "    threshold=0.05,\n",
    "    patience=5,\n",
    "    sindy_regularization=10.0,\n",
    "    optimizer=\"AdamW\",\n",
    "    thres_epoch=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test reconstruction error\n",
    "test_recons = sc.inverse_transform(shred(test_dataset.X).detach().cpu().numpy())\n",
    "test_ground_truth = sc.inverse_transform(test_dataset.Y.detach().cpu().numpy())\n",
    "\n",
    "relative_error = np.linalg.norm(test_recons - test_ground_truth) / np.linalg.norm(test_ground_truth)\n",
    "print(f\"Test set relative reconstruction error: {relative_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-recon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.pcolormesh(test_ground_truth.T, **pcolor_kwargs)\n",
    "ax.set_title(\"Ground Truth\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.pcolormesh(test_recons.T, **pcolor_kwargs)\n",
    "ax.set_title(\"SINDy-SHRED Reconstruction\")\n",
    "ax.set_ylabel(\"Space\")\n",
    "ax.set_xlabel(\"Time step\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{RESULTS_DIR}/reconstruction_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sindy-header",
   "metadata": {},
   "source": [
    "## 6. Post-hoc SINDy Discovery\n",
    "\n",
    "Extract latent trajectories and discover sparse governing equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-latent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent trajectories from training data\n",
    "gru_outs_train, _ = shred.gru_outputs(train_dataset.X, sindy=True)\n",
    "gru_outs_train = gru_outs_train[:, 0, :]\n",
    "\n",
    "# Normalize latent trajectories to [-1, 1]\n",
    "gru_outs_normalized = gru_outs_train.clone()\n",
    "for i in range(latent_dim):\n",
    "    gru_outs_normalized[:, i] = (gru_outs_train[:, i] - torch.min(gru_outs_train[:, i])) / \\\n",
    "                                 (torch.max(gru_outs_train[:, i]) - torch.min(gru_outs_train[:, i]))\n",
    "gru_outs_normalized = 2 * gru_outs_normalized - 1\n",
    "\n",
    "x_train = gru_outs_normalized.detach().cpu().numpy()\n",
    "gru_outs_train_np = gru_outs_train.detach().cpu().numpy()\n",
    "print(f\"Latent trajectories shape: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-discover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINDy discovery\n",
    "differentiation_method = ps.differentiation.FiniteDifference()\n",
    "\n",
    "model = ps.SINDy(\n",
    "    optimizer=ps.STLSQ(threshold=sindy_threshold, alpha=0.05),\n",
    "    differentiation_method=differentiation_method,\n",
    "    feature_library=ps.PolynomialLibrary(degree=poly_order),\n",
    ")\n",
    "\n",
    "model.fit(x_train, t=dt)\n",
    "print(\"\\nDiscovered SINDy equations:\")\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "true-eqns-header",
   "metadata": {},
   "source": [
    "### True Governing Equations\n",
    "\n",
    "**Slow modes (FitzHugh-Nagumo):**\n",
    "$$\\dot{v} = v - \\frac{1}{3}v^3 - w + 0.65$$\n",
    "$$\\dot{w} = \\frac{1}{\\tau_1}(v + 0.7 - 0.8w)$$\n",
    "with $\\tau_1 = 2$.\n",
    "\n",
    "**Fast modes (Duffing):**\n",
    "$$\\dot{p} = q$$\n",
    "$$\\dot{q} = -\\frac{1}{\\tau_2}(p + p^3)$$\n",
    "with $\\tau_2 = 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sindy-simulate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate discovered model\n",
    "t_sim = np.arange(0, len(x_train) * dt, dt)\n",
    "init_cond = x_train[0, :]\n",
    "x_sim = model.simulate(init_cond, t_sim)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(latent_dim, 1, figsize=(10, 2 * latent_dim), sharex=True)\n",
    "for i in range(latent_dim):\n",
    "    axes[i].plot(t_sim, x_train[:len(t_sim), i], label=\"SINDy-SHRED\")\n",
    "    axes[i].plot(t_sim, x_sim[:, i], \"k--\", label=\"Identified model\")\n",
    "    axes[i].set_ylabel(rf\"$z_{{{i}}}$\")\n",
    "    if i == latent_dim - 1:\n",
    "        axes[i].set_xlabel(\"Time\")\n",
    "        axes[i].legend()\n",
    "\n",
    "fig.suptitle(\"Latent Space: SINDy-SHRED vs Identified Model\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{RESULTS_DIR}/latent_comparison.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensor-pred-header",
   "metadata": {},
   "source": [
    "## 7. Sensor-Level Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensor-pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor-level comparisons (all spatial dimensions)\n",
    "fig, axes = plotting.plot_sensor_predictions(\n",
    "    test_ground_truth,\n",
    "    test_recons,\n",
    "    sensor_locations=np.arange(n_space_dims),\n",
    "    rows=2,\n",
    "    cols=5,\n",
    "    save_path=f\"{RESULTS_DIR}/sensor_predictions_grid.pdf\"\n",
    ")\n",
    "fig.suptitle(\"Sensor-Level Predictions: Real vs Reconstructed\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "torch.save(shred.state_dict(), f\"{RESULTS_DIR}/shred_model.pt\")\n",
    "print(f\"Saved SHRED model to {RESULTS_DIR}/shred_model.pt\")\n",
    "\n",
    "# Save latent trajectories\n",
    "np.save(f\"{RESULTS_DIR}/latent_train.npy\", x_train)\n",
    "print(f\"Saved latent trajectories\")\n",
    "\n",
    "# Save SINDy coefficients\n",
    "sindy_coefficients = model.coefficients()\n",
    "np.save(f\"{RESULTS_DIR}/sindy_coefficients.npy\", sindy_coefficients)\n",
    "print(f\"Saved SINDy coefficients: shape {sindy_coefficients.shape}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names = model.get_feature_names()\n",
    "with open(f\"{RESULTS_DIR}/sindy_feature_names.txt\", \"w\") as f:\n",
    "    for name in feature_names:\n",
    "        f.write(name + \"\\n\")\n",
    "\n",
    "# Save original data\n",
    "np.save(f\"{RESULTS_DIR}/data_original.npy\", data_original)\n",
    "np.save(f\"{RESULTS_DIR}/slow_modes.npy\", slow_modes)\n",
    "np.save(f\"{RESULTS_DIR}/fast_modes.npy\", fast_modes)\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    \"latent_dim\": latent_dim,\n",
    "    \"poly_order\": poly_order,\n",
    "    \"num_sensors\": num_sensors,\n",
    "    \"lags\": lags,\n",
    "    \"train_length\": train_length,\n",
    "    \"dt\": dt,\n",
    "    \"sindy_threshold\": sindy_threshold,\n",
    "    \"relative_error\": relative_error,\n",
    "}\n",
    "np.save(f\"{RESULTS_DIR}/config.npy\", config)\n",
    "\n",
    "print(\"\\nAll results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
